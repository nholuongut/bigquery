bq@gmail.com@example.comexample.comallAuthenticatedUsersallAuthenticatedUsersdataViewerdataViewerbigquery.datasets.getbigquery.tables.getDatabigquery.datasets.deletemetadataViewerroles/bigquery.metadataViewerdataViewerdataEditordataOwnerreadSessionUserjobUseruseradminbigquery.readSessionUserbigquery.tables.getDatajobUserSELECTdataEditorjobUserdataVieweruserdataViewerdataEditordataOwnerdataViewerdataEditordataOwnerjobUserdataViewerdataViewerjobUserdataEditordataSupplierdataSupplier.yamltitle: "Data Supplier"
description: "Can create, but not delete tables"
stage: "ALPHA"
includedPermissions:
- bigquery.datasets.get
- bigquery.tables.list
- bigquery.tables.get
- bigquery.tables.getData
- bigquery.tables.export
- bigquery.datasets.create
- bigquery.tables.create
- bigquery.tables.updateData
gcloudPROJECT=$(gcloud config get-value project)
gcloud iam roles create dataSupplier --project $PROJECT \
      --file dataSupplier.yaml
gcloud iam roles describe dataSupplier --project $PROJECT
ALPHABETAGA
dataViewerbigquery.tables.getDatadataViewerdataViewerdataViewerjobUserbqadminbqPENDINGRUNNINGSUCCESSFAILURENOW=$(date +%s)
START_TIME=$(echo "($NOW - 24*60*60)*1000" | bc)
bq --location=US ls -j -all --min_creation_time $START_TIME
bqmin_creation_timebcbq --location=US cancel bquxjob_180ae24c_16b04a8d28d
bq cancel someproject:US.bquxjob_180ae24c_16b04a8d28d
jobUseruseradminSYSTEM_TIME AS OFCREATE OR REPLACE TABLE ch10eu.restored_cycle_stations AS
SELECT 
  * 
FROM `bigquery-public-data`.london_bicycles.cycle_stations
FOR SYSTEM_TIME AS OF 
    TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
bq rm ch10eu.restored_cycle_stations
NOW=$(date +%s)
SNAPSHOT=$(echo "($NOW - 120)*1000" | bc) 
bq --location=EU cp \
   ch10eu.restored_cycle_stations@$SNAPSHOT \
   ch10eu.restored_table
from google.cloud import bigquery
def query_to_gcs():
client = bigquery.Client()

# Run query and wait for it to complete
query_job = client.query("""
    ...
    """)
query_job.result()

# Extract to GCS, and wait for it to complete
extract_job = client.extract_table(
    query_job.destination, "gs://bucket/file.csv")
extract_job.result()
extract_tablefrom google.cloud import bigquery
client = bigquery.Client()
sql = """
WITH stations AS (
   SELECT [300, 314, 287] AS closed
)
SELECT
  station_id
  , (SELECT name FROM `bigquery-public-data`.london_bicycles.cycle_stations WHERE id=station_id) AS name
FROM
  stations, UNNEST(closed) AS station_id
"""
job_config = bigquery.QueryJobConfig()
job_config.destination = ( client.dataset('ch10eu').table('stations_under_construction'))
query_job = client.query(sql, location='EU', job_config=job_config)
query_job.result()  # Waits for the query to finish

CREATE OR REPLACE TABLE -- or TABLE/MODEL/FUNCTION
ch10eu.stations_under_construction
(
  station_id INT64 OPTIONS(description = 'Station ID'),
  name string OPTIONS(description = 'Official station name')
)
OPTIONS(
    description = 'Stations in London.',
    labels=[("pii", "none")] -- Must be lowercase.
)
AS

WITH stations AS (
   SELECT [300, 314, 287] AS closed
)

SELECT
  station_id
  , (SELECT name FROM `bigquery-public-data`.london_bicycles.cycle_stations WHERE id=station_id) AS name
FROM
  stations, UNNEST(closed) AS station_id



SELECT
  invoice.month
  , product
  , ROUND(SUM(cost)
         + SUM(IFNULL((SELECT SUM(c.amount) FROM UNNEST(credits) c),
               0))
         , 2) AS monthly_cost
FROM ch10eu.gcp_billing_export_v1_XXXXXX_XXXXXX_XXXXXX
GROUP BY 1, 2
ORDER BY 1 ASC, 2 ASC
 labels.keylabels.valueteammarketingresearchenvironmentproductiontestbq update --set_label environment:learning ch10eu
bq update --set_label environment:learning ch10eu.restored_table
bq query --label environment:learning --nouse_legacy_sql 'SELECT 17'
labelsSELECT
  invoice.month
  , label.value
  , ROUND(SUM(cost)
         + SUM(IFNULL((SELECT SUM(c.amount) FROM UNNEST(credits) c),
               0))
         , 2) AS monthly_cost
FROM 
  ch10eu.gcp_billing_export_v1_XXXXXX_XXXXXX_XXXXXX
  , UNNEST(labels) AS label
WHERE
  label.key = 'environment'
GROUP BY 1, 2
ORDER BY 1 ASC, 2 ASC
WITH data as
  (
    SELECT
      protopayload_auditlog.authenticationInfo.principalEmail as principalEmail,
      protopayload_auditlog.servicedata_v1_bigquery.jobCompletedEvent AS jobCompletedEvent
    FROM
      ch10.cloudaudit_googleapis_com_data_access_2019*
  )
  SELECT
    principalEmail,
    SUM(jobCompletedEvent.job.jobStatistics.totalBilledBytes)/POWER(2, 40)) AS Estimated_USD_Cost
  FROM
    data
  WHERE
    jobCompletedEvent.eventName = 'query_job_completed'
  GROUP BY principalEmail
  ORDER BY Estimated_USD_Cost DESC
asia-east2bq --location=asia-east2 mk --dataset ch10hk
locationjobReferencebq--locationasia-east2ch10euCREATE OR REPLACE VIEW ch10eu.authorized_view_300 AS 
SELECT  
  * EXCEPT (bike_id, end_station_priority_id)
FROM 
  [PROJECTID].ch07eu.cycle_hire_clustered
WHERE
  start_station_id = 300 OR end_station_id = 300
bike_idch10euBigQuery Userch10euch07euch10euch07eu[PROJECT]https://console.cloud.google.com/bigquery?p=[PROJECT]&d=ch10eu&page=dataset
ch10euch07euSELECT AVG(duration)
FROM [PROJECT].ch10eu.authorized_view_300
SESSION_USER
CREATE OR REPLACE VIEW ecommerce.vw_large_transactions
OPTIONS(
  description="large transactions for review",
  labels=[('org_unit','loss_prevention')],
  expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 90 DAY)
)
AS

SELECT 
  visitorId,
  REGEXP_EXTRACT(SESSION_USER(), r'@(.+)') AS user_domain,
  REGEXP_EXTRACT(visitorEmailAddress, r'@(.+)') AS customer_domain,
  date,
  totals.transactions, 
  totals.transactionRevenue,
  totals.totalTransactionRevenue,
  totals.timeOnScreen
 
FROM `bigquery-public-data`.google_analytics_sample.ga_sessions_20170801 
 
WHERE
  (totals.totalTransactionRevenue / 1000000) > 1000 
  AND REGEXP_EXTRACT(visitorEmailAddress, r'@(.+)') = 
      REGEXP_EXTRACT(SESSION_USER(), r'@(.+)')
ORDER BY totals.totalTransactionRevenue DESC
LIMIT 10

@example.com@example.com@acme.comDELETEDELETE someds.user_transactions
WHERE
  userId = 'xyz'
MERGECREATE OR REPLACE TABLE ch10eu.encrypted_bike_keys AS
WITH bikes AS (
  SELECT
    DISTINCT bike_id
  FROM
    `bigquery-public-data`.london_bicycles.cycle_hire
)
SELECT 
   bike_id, KEYS.NEW_KEYSET('AEAD_AES_GCM_256') AS keyset 
FROM
   bikes
CREATE TEMPORARY FUNCTION encrypt_int(keyset BYTES, data INT64, trip_start TIMESTAMP) AS (
   AEAD.ENCRYPT(keyset, CAST(data AS STRING), CAST(trip_start AS STRING)) 
);
CREATE TEMPORARY FUNCTION encrypt_str(keyset BYTES, data STRING, trip_start TIMESTAMP) AS (
   AEAD.ENCRYPT(keyset, data, CAST(trip_start AS STRING)) 
);

CREATE OR REPLACE TABLE ch10eu.encrypted_cycle_hire AS

SELECT
    cycle_hire.* EXCEPT(start_station_id, end_station_id, start_station_name, end_station_name)
    , encrypt_int(keyset, start_station_id, start_date) AS start_station_id
    , encrypt_int(keyset, end_station_id, start_date) AS end_station_id
    , encrypt_str(keyset, start_station_name, start_date) AS start_station_name
    , encrypt_str(keyset, end_station_name, start_date) AS end_station_name    
FROM
    `bigquery-public-data`.london_bicycles.cycle_hire
JOIN
    ch10eu.encrypted_bike_keys
USING (bike_id)

start_station_idend_station_idstart_station_nameend_station_namekeysetbike_idbike_idCREATE TEMPORARY FUNCTION 
decrypt(keyset BYTES, encrypted BYTES, trip_start TIMESTAMP) AS (
   AEAD.DECRYPT_STRING(keyset, encrypted, CAST(trip_start AS STRING)) 
);

WITH duration_by_station AS (
  SELECT
      duration
      , decrypt(keyset, start_station_name, start_date) AS start_station_name
  FROM
      ch10eu.encrypted_cycle_hire
  JOIN
      ch10eu.encrypted_bike_keys
  USING (bike_id)
)

SELECT 
  start_station_name
  , AVG(duration) AS duration
FROM
  duration_by_station
GROUP BY
  start_station_name
ORDER BY duration DESC
LIMIT 5


SELECT COUNT (DISTINCT start_station_name)
FROM ch10eu.encrypted_cycle_hire

SELECT COUNT (DISTINCT start_station_name)
FROM `bigquery-public-data`.london_bicycles.cycle_hire
bike_idDELETE ch10eu.encrypted_bike_keys
WHERE bike_id = 300


gcloud kms keyrings create acmecorp --location US
gcloud kms keys create xyz --location US \
  --keyring acmecorp --purpose encryption \
  --rotation-period 30d \
  --next-rotation-time 2019-07-01T12:00:00Z
USUSasia-northeast1asia-northeast1SVC=$(bq show --encryption_service_account)
gcloud kms keys add-iam-policy-binding \
  --project=[KMS_PROJECT_ID] \
  --member serviceAccount:$SVC
  --role roles/cloudkms.cryptoKeyEncrypterDecrypter \
  --location=US \
  --keyring=acmecorp \
  xyz
bq mk â€¦ --destination_kms_key \
projects/[PROJECT_ID]/locations/US/keyRings/acmecorp/cryptoKeys/xyz \
mydataset.transactions

