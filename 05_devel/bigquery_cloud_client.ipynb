{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of using the Google Cloud Client Library for BigQuery\n",
    "\n",
    "This is the recommended way to programmatically access BigQuery.\n",
    "\n",
    "The API documentation is here: https://googleapis.github.io/google-cloud-python/latest/bigquery/reference.html. Because it is impossible to cover the full API, we strongly suggest that you have a browser window open to the documentation as you read through this notebook and try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install library and extensions if needed\n",
    "\n",
    "On Notebook instances on Google Cloud, the BigQuery client library is already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if necessary.\n",
    "# !python -m pip install --upgrade google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate and build stubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT='cloud-training-demos'  # CHANGE THIS\n",
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset manipulation\n",
    "\n",
    "Get info about a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch04\n",
      "2019-01-26 00:41:01.350000+00:00\n"
     ]
    }
   ],
   "source": [
    "# information about the ch04 dataset in our project\n",
    "dataset_id = \"{}.ch04\".format(PROJECT)\n",
    "dsinfo = bq.get_dataset(dataset_id)\n",
    "print(dsinfo.dataset_id)\n",
    "print(dsinfo.created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the project in the Client is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch04\n",
      "2019-01-26 00:41:01.350000+00:00\n"
     ]
    }
   ],
   "source": [
    "# information about the ch04 dataset in our project\n",
    "dsinfo = bq.get_dataset(\"ch04\")\n",
    "print(dsinfo.dataset_id)\n",
    "print(dsinfo.created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info about a dataset in some other project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london_bicycles created on 2017-05-25 13:26:18.055000+00:00\n"
     ]
    }
   ],
   "source": [
    "dsinfo = bq.get_dataset('bigquery-public-data.london_bicycles')\n",
    "print('{} created on {}'.format(dsinfo.dataset_id, dsinfo.created))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to create a dataset reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london_bicycles created on 2017-05-25 13:26:18.055000+00:00 in EU\n",
      "<AccessEntry: role=READER, specialGroup=allAuthenticatedUsers>\n",
      "<AccessEntry: role=READER, domain=google.com>\n",
      "<AccessEntry: role=READER, specialGroup=projectReaders>\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.bigquery.dataset import DatasetReference\n",
    "dsinfo = bq.get_dataset('bigquery-public-data.london_bicycles')\n",
    "print('{} created on {} in {}'.format(dsinfo.dataset_id, dsinfo.created, dsinfo.location))\n",
    "for access in dsinfo.access_entries:\n",
    "    if access.role == 'READER':\n",
    "        print(access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq.delete_dataset('ch05', not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch05 created on 2019-03-12 16:58:20.438000+00:00 in US\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"{}.ch05\".format(PROJECT)\n",
    "ds = bq.create_dataset(dataset_id, exists_ok=True)\n",
    "print('{} created on {} in {}'.format(ds.dataset_id, ds.created, ds.location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset in EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch05eu created on 2019-03-12 16:59:49.085000+00:00 in EU\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"{}.ch05eu\".format(PROJECT)\n",
    "dsinfo = bigquery.Dataset(dataset_id)\n",
    "dsinfo.location = 'EU'\n",
    "ds = bq.create_dataset(dsinfo, exists_ok=True)\n",
    "print('{} created on {} in {}'.format(ds.dataset_id, ds.created, ds.location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Chapter 5 of BigQuery: The Definitive Guide\n"
     ]
    }
   ],
   "source": [
    "dsinfo = bq.get_dataset(\"ch05\")\n",
    "print(dsinfo.description)\n",
    "dsinfo.description = \"Chapter 5 of BigQuery: The Definitive Guide\"\n",
    "dsinfo = bq.update_dataset(dsinfo, ['description'])\n",
    "print(dsinfo.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding access to a dataset programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<AccessEntry: role=WRITER, specialGroup=projectWriters>, <AccessEntry: role=OWNER, specialGroup=projectOwners>, <AccessEntry: role=OWNER, userByEmail=vlakshmanan@google.com>, <AccessEntry: role=READER, specialGroup=projectReaders>, <AccessEntry: role=READER, userByEmail=vlakshmanan@google.com>]\n"
     ]
    }
   ],
   "source": [
    "dsinfo = bq.get_dataset(\"ch05\")\n",
    "entry = bigquery.AccessEntry(\n",
    "    role=\"READER\",\n",
    "    entity_type=\"userByEmail\",\n",
    "    entity_id=\"vlakshmanan@google.com\",\n",
    ")\n",
    "if entry not in dsinfo.access_entries:\n",
    "  entries = list(dsinfo.access_entries)\n",
    "  entries.append(entry)\n",
    "  dsinfo.access_entries = entries\n",
    "  dsinfo = bq.update_dataset(dsinfo, [\"access_entries\"])  # API request\n",
    "else:\n",
    "  print('{} already has access'.format(entry.entity_id))\n",
    "print(dsinfo.access_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List tables in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle_hire\n",
      "cycle_stations\n"
     ]
    }
   ],
   "source": [
    "# list tables in dataset\n",
    "tables = bq.list_tables(\"bigquery-public-data.london_bicycles\")\n",
    "for table in tables:\n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View table properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 rows in cycle_stations (descr: None)\n",
      "SchemaField('bikes_count', 'INTEGER', 'NULLABLE', '', ())\n",
      "SchemaField('docks_count', 'INTEGER', 'NULLABLE', '', ())\n"
     ]
    }
   ],
   "source": [
    "table = bq.get_table(\"bigquery-public-data.london_bicycles.cycle_stations\")\n",
    "print('{} rows in {} (descr: {})'.format(table.num_rows, table.table_id, table.description))\n",
    "for field in table.schema:\n",
    "  if 'count' in field.name:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq.delete_table('ch05.temp_table', not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_table created on 2019-03-12 17:17:24.127000+00:00\n"
     ]
    }
   ],
   "source": [
    "table_id = '{}.ch05.temp_table'.format(PROJECT)\n",
    "table = bq.create_table(table_id, exists_ok=True)\n",
    "print('{} created on {}'.format(table.table_id, table.created))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F77wTFawTyp59e+U3hIMFg==\n",
      "[SchemaField('chapter', 'INTEGER', 'REQUIRED', None, ()), SchemaField('title', 'STRING', 'REQUIRED', None, ())]\n",
      "YdsTki4u3FOYeBXiHuHsrg==\n"
     ]
    }
   ],
   "source": [
    "schema = [\n",
    "  bigquery.SchemaField(\"chapter\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "  bigquery.SchemaField(\"title\", \"STRING\", mode=\"REQUIRED\"),\n",
    "]\n",
    "table_id = '{}.ch05.temp_table'.format(PROJECT)\n",
    "table = bq.get_table(table_id)\n",
    "print(table.etag)\n",
    "table.schema = schema\n",
    "table = bq.update_table(table, [\"schema\"])\n",
    "print(table.schema)\n",
    "print(table.etag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert rows into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_table 0\n",
      "[]\n",
      "temp_table 0\n"
     ]
    }
   ],
   "source": [
    "rows = [\n",
    "  (1, u'What is BigQuery?'),\n",
    "  (2, u'Query essentials'),\n",
    "]\n",
    "print(table.table_id, table.num_rows)\n",
    "errors = bq.insert_rows(table, rows)\n",
    "print(errors)\n",
    "table = bq.get_table(table_id)\n",
    "print(table.table_id, table.num_rows) # won't be updated because streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'index': 1, 'errors': [{'reason': 'invalid', 'location': 'chapter', 'debugInfo': '', 'message': 'Cannot convert value to integer (bad value):wont work'}]}, {'index': 0, 'errors': [{'reason': 'stopped', 'location': '', 'debugInfo': '', 'message': ''}]}, {'index': 2, 'errors': [{'reason': 'stopped', 'location': '', 'debugInfo': '', 'message': ''}]}]\n"
     ]
    }
   ],
   "source": [
    "## This will fail because the data type on the 2nd row is wrong\n",
    "rows = [\n",
    "  ('3', u'Operating on data types'),\n",
    "  ('wont work', u'This will fail'),\n",
    "  ('4', u'Loading data into BigQuery'),\n",
    "]\n",
    "errors = bq.insert_rows(table, rows)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an empty table with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_table2 created on 2019-03-12 17:19:25.915000+00:00\n",
      "[SchemaField('chapter', 'INTEGER', 'REQUIRED', None, ()), SchemaField('title', 'STRING', 'REQUIRED', None, ())]\n"
     ]
    }
   ],
   "source": [
    "schema = [\n",
    "  bigquery.SchemaField(\"chapter\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "  bigquery.SchemaField(\"title\", \"STRING\", mode=\"REQUIRED\"),\n",
    "]\n",
    "\n",
    "table_id = '{}.ch05.temp_table2'.format(PROJECT)\n",
    "table = bigquery.Table(table_id, schema)\n",
    "table = bq.create_table(table, exists_ok=True)\n",
    "print('{} created on {}'.format(table.table_id, table.created))\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the two temporary tables\n",
    "bq.delete_table('ch05.temp_table', not_found_ok=True)\n",
    "bq.delete_table('ch05.temp_table2', not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 rows into cloud-training-demos.ch05.temp_table3\n"
     ]
    }
   ],
   "source": [
    "bq.delete_table('ch05.temp_table3', not_found_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "data = [\n",
    "  (1, u'What is BigQuery?'),\n",
    "  (2, u'Query essentials'),\n",
    "]\n",
    "df = pd.DataFrame(data, columns=['chapter', 'title'])\n",
    "table_id = '{}.ch05.temp_table3'.format(PROJECT)\n",
    "job = bq.load_table_from_dataframe(df, table_id)\n",
    "job.result() # blocks and waits\n",
    "print(\"Loaded {} rows into {}\".format(job.output_rows, table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this appends rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows =  2\n",
      "Loaded 2 rows into cloud-training-demos.ch05.temp_table3\n",
      "Num rows =  4\n"
     ]
    }
   ],
   "source": [
    "print('Num rows = ', bq.get_table(table_id).num_rows)\n",
    "job = bq.load_table_from_dataframe(df, table_id)\n",
    "job.result() # blocks and waits\n",
    "print(\"Loaded {} rows into {}\".format(job.output_rows, table_id))\n",
    "print('Num rows = ', bq.get_table(table_id).num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the write disposition allows you to truncate the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows =  6\n",
      "Loaded 2 rows into cloud-training-demos.ch05.temp_table3\n",
      "Num rows =  2\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.bigquery.job import LoadJobConfig, WriteDisposition, CreateDisposition\n",
    "\n",
    "print('Num rows = ', bq.get_table(table_id).num_rows)\n",
    "load_config = LoadJobConfig(\n",
    "  create_disposition=CreateDisposition.CREATE_IF_NEEDED,\n",
    "  write_disposition=WriteDisposition.WRITE_TRUNCATE)\n",
    "job = bq.load_table_from_dataframe(df, table_id, job_config=load_config)\n",
    "job.result() # blocks and waits\n",
    "print(\"Loaded {} rows into {}\".format(job.output_rows, table_id))\n",
    "print('Num rows = ', bq.get_table(table_id).num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading from a URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................Done\n",
      "Loaded 7175 rows into college_scorecard_gcs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.null_marker = 'NULL'\n",
    "\n",
    "uri = \"gs://bigquery-oreilly-book/college_scorecard.csv\"\n",
    "table_id = '{}.ch05.college_scorecard_gcs'.format(PROJECT)\n",
    "job = bq.load_table_from_uri(uri, table_id, job_config=job_config)\n",
    "while not job.done():\n",
    "  print('.', end='', flush=True)\n",
    "  time.sleep(0.1)\n",
    "print('Done')\n",
    "table = bq.get_table(table_id)\n",
    "print(\"Loaded {} rows into {}.\".format(table.num_rows, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq.delete_table('ch05.college_scorecard_gcs', not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading from a file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................Done\n",
      "Loaded 14350 rows into college_scorecard_local.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gzip\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.null_marker = 'NULL'\n",
    "\n",
    "table_id = '{}.ch05.college_scorecard_local'.format(PROJECT)\n",
    "\n",
    "with gzip.open('../04_load/college_scorecard.csv.gz') as fp:\n",
    "  job = bq.load_table_from_file(fp, table_id, job_config=job_config)\n",
    "while not job.done():\n",
    "  print('.', end='', flush=True)\n",
    "  time.sleep(0.1)\n",
    "print('Done')\n",
    "table = bq.get_table(table_id)\n",
    "print(\"Loaded {} rows into {}.\".format(table.num_rows, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq.delete_table('ch05.college_scorecard_local', not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787\n"
     ]
    }
   ],
   "source": [
    "# copy london stations table to our dataset\n",
    "source_tbl = 'bigquery-public-data.london_bicycles.cycle_stations'\n",
    "dest_tbl = '{}.ch05eu.cycle_stations_copy'.format(PROJECT)\n",
    "job = bq.copy_table(source_tbl, dest_tbl, location='EU')\n",
    "job.result() # blocks and waits\n",
    "dest_table = bq.get_table(dest_tbl)\n",
    "print(dest_table.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting from a table to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET=PROJECT + '-eu-temp'\n",
    "!gsutil mb -l EU gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"381\",\"install_date\":\"2011-01-28\",\"installed\":true,\"latitude\":51.51953043,\"locked\":\"false\",\"longitude\":-0.13577731,\"name\":\"Charlotte Street, Fitzrovia\",\"bikes_count\":\"0\",\"docks_count\":\"14\",\"nbEmptyDocks\":\"14\",\"temporary\":false,\"terminal_name\":\"002669\"}\r\n",
      "{\"id\":\"82\",\"install_date\":\"2010-07-13\",\"installed\":true,\"latitude\":51.514274,\"locked\":\"false\",\"longitude\":-0.111257,\"name\":\"Chancery Lane, Holborn\",\"bikes_count\":\"0\",\"docks_count\":\"15\",\"nbEmptyDocks\":\"15\",\"temporary\":false,\"terminal_name\":\"003453\"}\r\n",
      "{\"id\":\"23\",\"install_date\":\"2010-07-06\",\"installed\":true,\"latitude\":51.51943538,\"locked\":\"false\",\"longitude\":-0.119123345,\"name\":\"Red Lion Square, Holborn\",\"bikes_count\":\"0\",\"docks_count\":\"16\",\"nbEmptyDocks\":\"16\",\"temporary\":false,\"terminal_name\":\"003421\"}\r\n",
      "{\"id\":\"56\",\"install_date\":\"2010-07-10\",\"installed\":true,\"latitude\":51.52058381,\"locked\":\"false\",\"longitude\":-0.154701411,\"name\":\"Paddington Street, Marylebone\",\"bikes_count\":\"0\",\"docks_count\":\"16\",\"nbEmptyDocks\":\"16\",\"temporary\":false,\"terminal_name\":\"001033\"}\r\n",
      "{\"id\":\"120\",\"install_date\":\"2010-07-15\",\"installed\":true,\"latitude\":51.51573534,\"locked\":\"false\",\"longitude\":-0.093080779,\"name\":\"The Guildhall, Guildhall\",\"bikes_count\":\"0\",\"docks_count\":\"17\",\"nbEmptyDocks\":\"16\",\"temporary\":false,\"terminal_name\":\"001044\"}\r\n"
     ]
    }
   ],
   "source": [
    "source_tbl = 'bigquery-public-data.london_bicycles.cycle_stations'\n",
    "dest_uri = 'gs://{}/tmp/exported/cycle_stations'.format(BUCKET)\n",
    "config = bigquery.job.ExtractJobConfig(\n",
    "  destination_format=bigquery.job.DestinationFormat.NEWLINE_DELIMITED_JSON)\n",
    "job = bq.extract_table(source_tbl, dest_uri, location='EU', job_config=config)\n",
    "job.result() # blocks and waits\n",
    "\n",
    "!gsutil cat $dest_uri | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil rm -rf gs://$BUCKET\n",
    "!gsutil rb -f gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows = 787\n",
      "Extracting only [SchemaField('id', 'INTEGER', 'NULLABLE', '', ()), SchemaField('bikes_count', 'INTEGER', 'NULLABLE', '', ()), SchemaField('docks_count', 'INTEGER', 'NULLABLE', '', ())]\n",
      "id         bikes_count docks_count \n",
      "689        9          30         \n",
      "345        9          33         \n",
      "644        9          36         \n",
      "365        9          47         \n",
      "404        10         13         \n"
     ]
    }
   ],
   "source": [
    "table_id = 'bigquery-public-data.london_bicycles.cycle_stations'\n",
    "table = bq.get_table(table_id)\n",
    "print(\"Total number of rows = {}\".format(table.num_rows)) # 787\n",
    "fields = [field for field in table.schema \n",
    "                if 'count' in field.name or field.name == 'id']\n",
    "print(\"Extracting only {}\".format(fields))\n",
    "rows = bq.list_rows(table, \n",
    "                    start_index=300, \n",
    "                    max_results=5, \n",
    "                    selected_fields=fields)\n",
    "fmt = '{!s:<10} ' * len(rows.schema)\n",
    "print(fmt.format(*[field.name for field in rows.schema]))\n",
    "for row in rows:\n",
    "  print(fmt.format(*row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query and get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT \n",
      "  start_station_name \n",
      "  , AVG(duration) as duration\n",
      "  , COUNT(duration) as num_trips\n",
      "FROM `bigquery-public-data`.london_bicycles.cycle_hire \n",
      "GROUP BY start_station_name \n",
      "ORDER BY num_trips DESC\n",
      "LIMIT 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  start_station_name \n",
    "  , AVG(duration) as duration\n",
    "  , COUNT(duration) as num_trips\n",
    "FROM `bigquery-public-data`.london_bicycles.cycle_hire \n",
    "GROUP BY start_station_name \n",
    "ORDER BY num_trips DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dry run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query will process 903989528 bytes.\n"
     ]
    }
   ],
   "source": [
    "config = bigquery.QueryJobConfig()\n",
    "config.dry_run = True\n",
    "job = bq.query(query, location='EU', job_config=config)\n",
    "print(\"This query will process {} bytes.\".format(job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgrove Street , King's Cross                 1011     234458\n",
      "Hyde Park Corner, Hyde Park                    2783     215629\n",
      "Waterloo Station 3, Waterloo                    866     201630\n",
      "Black Lion Gate, Kensington Gardens            3588     161952\n",
      "Albert Gate, Hyde Park                         2359     155647\n",
      "Waterloo Station 1, Waterloo                    992     145910\n",
      "Wormwood Street, Liverpool Street               976     119447\n",
      "Hop Exchange, The Borough                      1218     115135\n",
      "Wellington Arch, Hyde Park                     2276     110260\n",
      "Triangle Car Park, Hyde Park                   2233     108347\n"
     ]
    }
   ],
   "source": [
    "# send query request\n",
    "job = bq.query(query, location='EU')\n",
    "fmt = '{!s:<40} {:>10d} {:>10d}'\n",
    "for row in job:\n",
    "    fields = (row['start_station_name'], \n",
    "              (int)(0.5 + row['duration']), \n",
    "              row['num_trips']) \n",
    "    print(fmt.format(*fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query result to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          duration      num_trips\n",
      "count   880.000000     880.000000\n",
      "mean   1348.351153   27692.273864\n",
      "std     434.057829   23733.621289\n",
      "min       0.000000       1.000000\n",
      "25%    1078.684974   13033.500000\n",
      "50%    1255.889223   23658.500000\n",
      "75%    1520.504055   35450.500000\n",
      "max    4836.380090  234458.000000\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  start_station_name \n",
    "  , AVG(duration) as duration\n",
    "  , COUNT(duration) as num_trips\n",
    "FROM `bigquery-public-data`.london_bicycles.cycle_hire \n",
    "GROUP BY start_station_name\n",
    "\"\"\"\n",
    "df = bq.query(query, location='EU').to_dataframe()\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameterized query to get only trips longer than some duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT \n",
      "  start_station_name \n",
      "  , COUNT(duration) as num_trips\n",
      "FROM `bigquery-public-data`.london_bicycles.cycle_hire \n",
      "WHERE duration >= @min_duration\n",
      "GROUP BY start_station_name \n",
      "ORDER BY num_trips DESC\n",
      "LIMIT 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "  start_station_name \n",
    "  , COUNT(duration) as num_trips\n",
    "FROM `bigquery-public-data`.london_bicycles.cycle_hire \n",
    "WHERE duration >= @min_duration\n",
    "GROUP BY start_station_name \n",
    "ORDER BY num_trips DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "print(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyde Park Corner, Hyde Park                  203592\n",
      "Belgrove Street , King's Cross               168110\n",
      "Waterloo Station 3, Waterloo                 148809\n",
      "Albert Gate, Hyde Park                       145794\n",
      "Black Lion Gate, Kensington Gardens          137930\n",
      "Waterloo Station 1, Waterloo                 106092\n",
      "Wellington Arch, Hyde Park                   102770\n",
      "Triangle Car Park, Hyde Park                  99368\n",
      "Wormwood Street, Liverpool Street             82483\n",
      "Palace Gate, Kensington Gardens               80342\n"
     ]
    }
   ],
   "source": [
    "config = bigquery.QueryJobConfig()\n",
    "config.query_parameters = [\n",
    "  bigquery.ScalarQueryParameter('min_duration', \"INT64\", 600)\n",
    "]\n",
    "job = bq.query(query2, location='EU', job_config=config)\n",
    "fmt = '{!s:<40} {:>10d}'\n",
    "for row in job:\n",
    "    fields = (row['start_station_name'], \n",
    "              row['num_trips']) \n",
    "    print(fmt.format(*fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
